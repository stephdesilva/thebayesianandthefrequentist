<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.40.1" />


<title>Let&#39;s break some p-values - Part 1 - The Bayesian and the Frequentist</title>
<meta property="og:title" content="Let&#39;s break some p-values - Part 1 - The Bayesian and the Frequentist">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/stephdesilva/thebayesianandthefrequentist">GitHub</a></li>
    
    <li><a href="https://twitter.com/thebayesianand1">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">14 min read</span>
    

    <h1 class="article-title">Let&#39;s break some p-values - Part 1</h1>

    
    <span class="article-date">2019-03-19</span>
    

    <div class="article-content">
      <p><strong>Intended level and assumed knowledge</strong>: <em>We figure you know a little about probability, a little about R, a little about hypothesis testing and statistics. We’d like to show you how these fit together. If you’re unfamiliar with these concepts, the footnotes will be your guide (some of the time).</em></p>
<div id="and-so-it-begins.." class="section level2">
<h2>And so it begins..</h2>
<p><em>Our location: an office somewhere in Sydney, Australia. It might be well-appointed corporate digs, a slightly underfunded academic building or a cheap cafe somewhere in central Sydney. Choose your own statistical adventure.</em><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p><strong>John</strong>: Where do you want to start Steph?</p>
<p><strong>Steph</strong>: I don’t know, John. I have a lot of pent up rage. Let’s break something.</p>
<p><strong>John</strong>: We both know you have issues, Steph. We could take a stab<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> at
making sense of the reproducibility of experiments, prediction, and pre-registration?
Even better, we could take a stab at <em>truth</em>.</p>
<p><strong>Steph</strong>: Literally?</p>
<p><strong>John</strong>: Figuratively. We could look at hypothesis testing. We planned to do something useful, remember?</p>
<p><strong>Steph</strong>: OK, let’s break a hypothesis test. But these concepts are all really complex. Explain it like … I’m a management consultant. There should be a powerpoint and a snappy title.</p>
<p><strong>John</strong>: No chance. I’ll explain it like I’m a professor of statistics.</p>
<p><strong>Steph</strong>: My way is funnier. You and Microsoft SmartArt. Just give me five minutes to put a bet down with your grad students.</p>
<p><strong>John</strong>: My way at least makes sense and has an actual point.</p>
<p><strong>Steph</strong>: Fair call. OK, go!</p>
<p><strong>John</strong>: Alright, it started a few years ago. People started looking into whether
particular bits of medical research were reproducible. In particular
<span class="citation">Ioannidis (<a href="#ref-Ioannidis2005">2005</a>)</span> tried to reproduce 49 famous medical publications from
1990-2003 resulting from randomized trials: 45 claimed successful
intervention;</p>
<ul>
<li>7 (16%) were contradicted;</li>
<li>7 others (16%) found effect sizes were exaggerated;</li>
<li>20 (44%) were replicated; and</li>
<li>11 (24%) remained largely unchallenged.</li>
</ul>
<p><strong>John</strong>: There were a number of other papers too, like <span class="citation">Pashler and Wagenmakers (<a href="#ref-PashlerWagenmakers2012">2012</a>)</span>.
The common theme between all of these papers, statistically speaking, is hypothesis testing.</p>
<p>One approach at fixing this problem is to pre-register hypothesis testing procedures.</p>
<p><strong>Steph</strong>: This plan as not dreamed up by management consultants. Why did they take that approach?</p>
<p><strong>John</strong>: Well people tended to play around with their analysis by playing
games with statistics to get statistical significance (usually <span class="math inline">\(p\)</span>-values
below 0.05). Pre-registration is the idea that forces researchers to pre-specify
how they will analyse their data before they collect it to stop this from happening.</p>
<p><strong>Steph</strong>: And yet we do it all the time with exploratory analysis.</p>
<p><strong>John</strong>: But causal inference needs a different approach.</p>
<p><strong>Steph</strong>: I agree, but as the person who wanted to stab a theoretical concept earlier in this conversation, I can think of a whole bunch of ways this can go wrong.</p>
<p><strong>John</strong>: Exactly. It’s really imperfect, but I think it would help to explain <em>why</em> that’s the case.</p>
<p><strong>Steph</strong>: You know what this dialogue needs, John?</p>
<p><strong>John</strong>: You’re going to tell me, whether I want to hear it or not.</p>
<p><strong>Steph</strong>: Relateable examples, mate.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p><strong>John</strong> (thinks): OK so a few years ago my wife was rear-ended while driving and the
car was written off so we needed to buy a new car. While we were looking to
get a new car my sister in law asked (as a joke) “Are you getting a red car?
I heard they’re fast!”</p>
<p><img src="lamborghini_huracan_slideshow_lead.jpg" style="width:90%"></p>
<p><strong>John</strong>: Now I don’t know much about cars at all. So if I went into a
car yard I wouldn’t want to buy one that looked like this.</p>
<p><strong>Steph</strong>: Honestly, John, it’s really not your style. You’re totally not doing the whole mid life crisis thing.</p>
<p><strong>John</strong>: Fast cars are also expensive cars! But that’s not the point.</p>
<p><strong>Steph</strong>: Your midlife crisis is not the point?</p>
<p><strong>John</strong>: I’m not having a midlife crisis.</p>
<p><strong>Steph</strong>: You’re an academic statistician who just started a blog with a management consultant.</p>
<p><strong>John</strong>: My judgement is lacking sometimes. There’s a point to this post though- I wanted to look at a bunch of ways to mess around with hypothesis tests in order
to get them to break.</p>
<p>My first example related to my sister in law’s joke.</p>
<p>By <em>break</em> I mean that the results of the hypothesis test are misleading - I want to create a situation where the test is telling us there is a difference between
two things when in fact no difference exists in reality.</p>
<p><strong>Steph</strong>: <em>Bayesians</em>. Let’s do this, let’s break some hypothesis tests, I might be the frequentist in this conversation, but the fact is that inference is really, really breakable in the field, so I think this is inherently useful. Bring on the cars!</p>
</div>
<div id="red-cars-are-faster4" class="section level1">
<h1>Red cars are faster!<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></h1>
<p>Let’s imagine a simplified world, such as is suitable for management consultants and students of statistics:</p>
<p>Suppose that<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<ul>
<li><p>There are only two car colours -
<span style="color:red"><strong>red</strong></span> cars and
<span style="color:blue"><strong>blue</strong></span> cars
and we describe them with the variable <span class="math inline">\(\mbox{colour}_i\)</span>;</p></li>
<li><p>Cars can eiher be <span style="color:purple"><strong>sports</strong></span> cars or
<span style="color:green"><strong>normal</strong></span> cars;
and we represent them with the variable <span class="math inline">\(\mbox{type}_i\)</span>;</p></li>
<li><p><span style="color:purple"><strong>Sports</strong></span> cars
are more likely to be <span style="color:red"><strong>red</strong></span>
than <span style="color:green"><strong>normal</strong></span> cars</p></li>
<li><p><span style="color:purple"><strong>Sports</strong></span> cars
are generally faster than
<span style="color:green"><strong>normal</strong></span> cars.</p></li>
</ul>
<p>The relationship between the three variables can
be visualized by a directed acyclic graph.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>There are three nodes: type, colour and speed. The car type “causes”
the car colour and the car speed so there is a directed
edge from type to colour and type to speed. We can visualize this
using the <code>dagitty</code> and <code>ggdag</code> packages <span class="citation">(Textor and van der Zander <a href="#ref-R-dagitty">2016</a>,<span class="citation">@R-ggdag</span>)</span>.</p>
<pre class="r"><code>library(dagitty)
library(ggdag)</code></pre>
<pre><code>## 
## Attaching package: &#39;ggdag&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     expand_scale</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre class="r"><code>dagified &lt;- dagify(colour ~ type,
                   speed ~ type,
                   exposure = &quot;x&quot;,
                   outcome = &quot;speed&quot;)
ggdag(dagified, layout = &quot;circle&quot;)</code></pre>
<div class="figure"><span id="fig:fig-margin1"></span>
<img src="/post/pvalues_tufte_files/figure-html/fig-margin1-1.png" alt="DAG for speed, colour and type" width="336" />
<p class="caption">
Figure 1: DAG for speed, colour and type
</p>
</div>
<p>That was all a bit <em>mathy</em>, but the general upshot is that we created a little facsimile of the world, one in which there are two types of cars (sports and normal), two colours of cars (blue and red) and cars have a speed that depends on their type (or purpose). Then we represented it with some circles and lines that describe what those relationships are.</p>
</div>
<div id="simulating-data" class="section level1">
<h1>Simulating data</h1>
<p>Let’s put some numbers around this to create a concrete example: something measurable that we can test, and then show how and where a hypothesis test can (and does) get it wrong.</p>
<p>Let’s say that each type of car is equally likely:</p>
<p><span class="math display">\[
\begin{array}{rl}
{\mathbb P}( \mbox{sports car}  ) = 0.5 \\
{\mathbb P}( \mbox{normal car}  ) = 0.5 \\
\end{array}
\]</span></p>
<p>Next, let’s say that the probability of a sports car being red is higher than for a normal car.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p><span class="math display">\[
\begin{array}{rl}
{\mathbb P}( \mbox{red car} | \mbox{sports car}  ) &amp; = 0.8, \\
{\mathbb P}( \mbox{blue car} | \mbox{sports car}  ) &amp; = 0.2, \\
{\mathbb P}( \mbox{red car} | \mbox{normal car}  ) &amp; = 0.2, \qquad \mbox{and} \\
{\mathbb P}( \mbox{blue car} | \mbox{normal car}  ) &amp; = 0.8. \\
\end{array}
\]</span></p>
<p>Finally, suppose that normal cars travel on average <span class="math inline">\(\beta_0 = 100\)</span>km/h,
with sports cars travelling on average <span class="math inline">\(\beta_1 = 50km/h\)</span> higher,
with the same standard deviation of <span class="math inline">\(\sigma=25\)</span>km/h.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>Now, say there are lots of cars in the world. Statistics is usually about understanding patterns in repeated things. Then we can simulate the speed of the <span class="math inline">\(i\)</span>th car, where <span class="math inline">\(i\)</span> is just any arbitrary car, as:</p>
<p><span class="math display">\[
\begin{array}{rl}
\mbox{speed}_i 
&amp;  = \beta_0 + \beta_1 \times {\mathbb I}(\mbox{type}_i=\mbox{sports}) + \varepsilon_i  
\\
&amp;  = 100 + 50 \times {\mathbb I}(\mbox{type}_i=\mbox{sports}) + \varepsilon_i 
\end{array}
\]</span>
where independently <span class="math inline">\(\varepsilon_i \sim N(0,25^2)\)</span>.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<p><strong>Steph</strong>: John, you know that some people exist who are allergic to maths, right? So to translate, you made up a situation where the speed of the car is
only is related to the colour of the car because
red cars are more likely to be sports cars.</p>
<p><strong>John</strong>: Exactly, and this is going to be relevant later.</p>
<p>Let’s simulate some data<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> that captures this scenario using R <span class="citation">(R Core Team <a href="#ref-R-base">2018</a>)</span>.</p>
<pre class="r"><code># Specify true values of parameters
prob_sport &lt;- 0.5
prob_red_given_sport  &lt;- 0.8
prob_red_given_normal &lt;- 0.2
beta0  &lt;- 100
beta1  &lt;- 50
sd_Val &lt;- 25
n_cars &lt;- 50

# Simulate car type
type &lt;- rbinom(n_cars,1,prob_sport)

# Calculate colour probabilities according to type
prob_colour &lt;- ifelse(type,prob_red_given_sport,prob_red_given_normal)

# Simulate car colours
colour &lt;- rbinom(n_cars,1,prob_colour)

# Simulate car speeds
speed &lt;- beta0 + beta1*type + rnorm(n_cars,sd=sd_Val)

# Convert to tibble and make categories readible
tib &lt;- tibble(colour, speed) %&gt;% 
  mutate(
    colour=factor(
        ifelse(colour,&quot;red&quot;,&quot;blue&quot;),
          levels=c(&quot;red&quot;,&quot;blue&quot;)
        )
  )</code></pre>
<pre class="marginfigure"><code>__Steph__: Car type - where&#39;s the car type?

__John__: We&#39;re going to break this hypothesis test by dropping
an important variable.

__Steph__: Breaking, just like I asked for. I note we&#39;re breaking frequentist stuff first.

__John__: We&#39;re also simulating a podcast here, for reasons unknown.</code></pre>
</div>
<div id="boxplots-and-two-sample-t-tests-8" class="section level1">
<h1>Boxplots and two sample t-tests<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></h1>
<p>Now that we have simulated some data we can create boxplots and try
some statistical tests. If we make a boxplot for speed against colour
we get:</p>
<pre class="r"><code>p &lt;- ggplot(tib, aes(x=colour, y=speed, fill=colour)) + 
  geom_boxplot() +
  theme_bw()
p</code></pre>
<div class="figure"><span id="fig:fig-margin2"></span>
<img src="/post/pvalues_tufte_files/figure-html/fig-margin2-1.png" alt="speed vs colour" width="336" />
<p class="caption">
Figure 2: speed vs colour
</p>
</div>
<p>We see that there appears to be a clear difference between the speeds of
red and blue cars from the boxplots.</p>
<p>To quantify the difference a two sample <span class="math inline">\(t\)</span>-test could be used.
We have two sets of points
<span class="math display">\[
{\bf x} = (x_1,\ldots,x_n) \qquad \mbox{and} \qquad {\bf y} = (y_1,\ldots,y_m),
\]</span>
corresponding to the speeds of the red and blue cars respectively.
We assume that both the <span class="math inline">\({\bf x}\)</span> and <span class="math inline">\({\bf y}\)</span> samples are
normally distributed:
<span class="math display">\[
x_i \stackrel{iid.}{\sim} N(\mu_1,\sigma^2), 
\qquad \mbox{and} \qquad
y_i \stackrel{iid.}{\sim} N(\mu_2,\sigma^2) 
\]</span>
where the index ranges are <span class="math inline">\(i=1,\ldots,n\)</span> and <span class="math inline">\(i=1,\ldots,m\)</span>,
<span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span> are the mean speeds of the red and blue cars
respectively, and <span class="math inline">\(\sigma^2\)</span> is a common
variance parameter. Let’s
consider a hypothesis test of the form
<span class="math display">\[
H_0 \colon \mu_1 = \mu_2 \qquad \mbox{versus} \qquad H_1 \colon \mu_1 &gt; \mu_2  
\]</span>
where we have chosen a one sided alternative to indicate our prior
belief that red cars are faster than blue cars.</p>
<p>If we wanted to see if red cars were significantly faster than
blue cars we could perform a <span class="math inline">\(t\)</span> test using the
<code>tadaatoolbox</code> package <span class="citation">(Burk and Anton <a href="#ref-R-tadaatoolbox">2018</a>)</span>.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<pre class="r"><code>library(tadaatoolbox)
tadaa_t.test(data=tib, 
             response=speed, 
             group=colour, 
             direction=&quot;greater&quot;,
             print=&quot;markdown&quot;)</code></pre>
<p>Table 1: <strong>Two Sample t-test</strong> with alternative hypothesis: <span class="math inline">\(\mu_1 &gt; \mu_2\)</span></p>
<table>
<thead>
<tr class="header">
<th align="center">Diff</th>
<th align="center"><span class="math inline">\(\mu_1\)</span> red</th>
<th align="center"><span class="math inline">\(\mu_2\)</span> blue</th>
<th align="center">t</th>
<th align="center">SE</th>
<th align="center">df</th>
<th align="center"><span class="math inline">\(CI_{95\%}\)</span></th>
<th align="center">p</th>
<th align="center">Cohen's d</th>
<th align="center">Power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">40.12</td>
<td align="center">145.98</td>
<td align="center">105.86</td>
<td align="center">4.15</td>
<td align="center">9.66</td>
<td align="center">48</td>
<td align="center">(23.92 - Inf)</td>
<td align="center">&lt; .001</td>
<td align="center">1.2</td>
<td align="center">0.99</td>
</tr>
</tbody>
</table>
<p><br></p>
<p><br></p>
<p>We get statistical significance, which we’d expect because we set up our little universe that way. Fantastic, we didn’t break our own test! (Just Steph’s development environment).</p>
</div>
<div id="reproducibility-prediction-and-inference" class="section level1">
<h1>Reproducibility, prediction and inference</h1>
<p>Suppose that we went to a number of “car yards” (i.e., repeated the
experiment) where data was generated using the above process and we
<strong>only</strong> observed:</p>
<ul>
<li><p>the speed of the cars and the</p></li>
<li><p>the colour of the cars.</p></li>
</ul>
<p>Suppose that we repeated the experiment 1000 times, that is we went to 1000 car yards
and performed the same two sample t-test on different collected
samples at each car yard collecting data for <span class="math inline">\(n=50\)</span> different cars
each time.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<p>How often would red cars be significantly faster than blue car
if we were to repeat the same experiment over and over again,
i.e., would our results be reproducible?</p>
<pre class="r"><code># Authors&#39; note: when Steph had to buy a car, she gave up after the first 
# car yard and asked her friend who worked at said car yard to sort her 
# out. She bought the first car she test drove because she is a great 
# believer in not doing boring things, like car yards.
n_car_yards &lt;- 1000 

p_values &lt;- c()
for (i in 1:n_car_yards)
{
  # Simulate car type
  type &lt;- rbinom(n_cars,1,prob_sport)
  
  # Calculate colour probs
  prob_colour &lt;- ifelse(type,prob_red_given_sport,prob_red_given_normal)
  
  # Simulate car colours
  colour &lt;- rbinom(n_cars,1,prob_colour)
  
  # Simulate car speeds
  speed &lt;- beta0 + beta1*type + rnorm(n_cars,sd=sd_Val)

  # Perform two-sample t-test
  p_values[i] &lt;- t.test(speed[colour==1],
                        speed[colour==0],
                        alternative=&quot;greater&quot;)$p.value
}</code></pre>
<p>From the above simulations we find that in 94.1 percent
of simulations where red cars were statistically significantly faster than blue cars
even though the colour of the car has nothing to do with the speed of the car!</p>
<p>So…</p>
<ul>
<li><p><strong>Reproducibility</strong>: The results would be reproducible roughly
94.1 percent of the time since
if we went from car yard to car yard red cars would be generally faster
than blue cars. <em>Pre-registration does not inherently solve this problem of a <em>spurious relationship</em> between these variables.</em></p></li>
<li><p><strong>Prediction</strong>: Even though there is no direct relationship
between speend and car colour, if we were to pick a car that we wanted
to be fast then we would pick a red car and the car would be more likely to be
faster than if we picked a blue car.
We can still make good predictions from incorrect models.</p></li>
<li><p><strong>Truth</strong>: But painting our car red would not make it any faster.</p></li>
</ul>
<p><strong>Steph</strong>: Congratulations John, statistics has discovered the age-old econometric problem of the spurious regression. We broke that hypothesis because we were measuring the wrong relationships.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<p><strong>John</strong>: Yes, that was my point. With a relateable example. It occurs all the time
in science. Researchers don’t know what the true relationship between measurements
are so they</p>
<ul>
<li><p>measure what their current theory tells them what is important to measure;</p></li>
<li><p>measure what it is possible or convenient to measure; or</p></li>
<li><p>measure a whole bunch of stuff and hope that something they measure is important.</p></li>
</ul>
<p><strong>Steph</strong>: This happens in field work all.the.time. You think you’re measuring Thing A, when actually Thing B is what’s doing the heavy lifting and Thing B just happens to be correlated with Thing A. (Tylyer Vigen’s site is full of examples of this in real life)[<a href="http://www.tylervigen.com/spurious-correlations" class="uri">http://www.tylervigen.com/spurious-correlations</a>], in that case, <em>time itself</em> is the common Thing B. If you’re working with time series it’s often inevitable without recognising the impact it has.</p>
<p><strong>John</strong>: Stories for another day?</p>
<p><strong>Steph</strong>: Sure- next time let’s see what this idea of a <em>spurious relationship</em> would look like in a real-world data science context.</p>
<p><br></p>
<p><br></p>
<p><strong>Acknowledgements</strong>: We would like to thank
Sarah Romanes,
Isabella Ghement, and
Shila Ghazanfar
for proof-reading and comments.</p>
<p><br></p>
<p><br></p>
<div id="refs" class="references">
<div id="ref-R-ggdag">
<p>Barrett, Malcolm. 2018. <em>Ggdag: Analyze and Create Elegant Directed Acyclic Graphs</em>. <a href="https://CRAN.R-project.org/package=ggdag" class="uri">https://CRAN.R-project.org/package=ggdag</a>.</p>
</div>
<div id="ref-R-tadaatoolbox">
<p>Burk, Lukas, and Tobias Anton. 2018. <em>Tadaatoolbox: Helpers for Data Analysis and Presentation Focused on Undergrad Psychology</em>. <a href="https://CRAN.R-project.org/package=tadaatoolbox" class="uri">https://CRAN.R-project.org/package=tadaatoolbox</a>.</p>
</div>
<div id="ref-Ioannidis2005">
<p>Ioannidis, John P. A. 2005. “Contradicted and Initially Stronger Effects in Highly Cited Clinical Research.” <em>JAMA</em> 294 (2): 218–28.</p>
</div>
<div id="ref-PashlerWagenmakers2012">
<p>Pashler, Harold, and Eric–Jan Wagenmakers. 2012. “Editors’ Introduction to the Special Section on Replicability in Psychological Science: A Crisis of Confidence?” <em>Perspectives on Psychological Science</em> 7 (6): 528–30.</p>
</div>
<div id="ref-R-base">
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-R-dagitty">
<p>Textor, Johannes, and Benito van der Zander. 2016. <em>Dagitty: Graphical Analysis of Structural Causal Models</em>. <a href="https://CRAN.R-project.org/package=dagitty" class="uri">https://CRAN.R-project.org/package=dagitty</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>On our Twitter post announcing this blog, Steph made a comment about a would-be podcast, except she and John are the parents of five young kids between them (not together, we hasten to add). Consider this the ‘could have been’ podcast.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Australian slang for try.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>At this point, Steph attempted to compile this post for the first time. John, we need to talk about dependencies one of these days.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Now I’ve had to make a version update to R itself, John. I’m just saying, if you ever had to put code into production…<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>For the record, this proof is John’s but Steph had time to take all the math-speak away while trying to update all those dependencies. Y’all can thank me later.<a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p><em>Some maths help</em>: This is basically just choose your own adventure, but for probability - Steph.<a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p><em>Some maths help</em>: These are what we call <em>conditional probabilities</em>, the idea that if Thing 1 happens, then Thing 2 may be more or less likely as a result. This makes sense if you think about sports at all (neither John or Steph follow sport, but we hear that normal people often quite like it) - the probability of team A winning the sportsball grandfinal might be 50% overall. This is the <em>marginal</em> probability. But the probability that Team A wins the sportsball grandfinal <em>given</em> Team B’s star player mysteriously won free first class tickets to Las Vegas may be 90%. This is the <em>conditional</em> probability.<a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Am now reinstalling all dependencies of ggplot2, we better break something real good, John.<a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>As a corporate data scientist who is currently working through dependency hell, I legit use these all.the.time.<a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>The idea here is that we have very little certainty about one observation, but about many observations we can be <em>more</em> certain. And if anybody has any idea why this build is <em>Failed with error: ‘package ’ggplot2’ could not be loaded’</em>, I’d be eternally grateful.<a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>Am now reinstalling all dependencies of ggplot2, we better break something real good, John.<a href="#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>As a corporate data scientist who is currently working through dependency hell, I legit use these all.the.time.<a href="#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>The idea here is that we have very little certainty about one observation, but about many observations we can be <em>more</em> certain. And if anybody has any idea why this build is <em>Failed with error: ‘package ’ggplot2’ could not be loaded’</em>, I’d be eternally grateful.<a href="#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>I admit defeat, can’t work out the dependency issue, John hit me up with your dependencies and system environment please!<a href="#fnref14" class="footnote-back">↩</a></p></li>
</ol>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

