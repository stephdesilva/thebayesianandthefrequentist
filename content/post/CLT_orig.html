---
title: "The Central Limit Theorem"
author: "Steph and John"
date: '2019-04-04'
slug: p-values
tags: p-values
categories:
- Bayes
- Frequentist
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
    keep_tex: true
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
    keep_tex: true
link-citations: yes

---



<div id="why-are-we-here-and-how-did-this-become-a-blog-about-theoretical-statistics" class="section level1">
<h1>Why are we here and how did this become a blog about theoretical statistics?</h1>
<p>Most people find theoretical statistics garbage. Both Steph and John have stopped many a dinner party in its tracks with long and passionate discourses on the subject. However, we’ve both found a lot of value under the years in understanding <em>what’s going on under the hood</em>.</p>
<pre><code>* When do statistics break? (We like to break things alot around here)
* When can we expect them to work? (Despite evidence produced in this blog, they do work at least some of the time)
* What does the trade off between broken statistics and not-broken theory mean in practice?</code></pre>
<p>These questions are where our focus lies.</p>
<p>One of the most important things to understand about theoretical statistics is something called the <em>Central Limit Theorem</em>. It’s the engine in the <a href="https://www.thebayesianandthefrequentist.com/2019/03/18/p-values/">red sports car of statistics</a>. Many hypothesis tests need it to be true, a bewildering number of models require it to be working <a href="https://fivethirtyeight.com/features/the-polls-missed-trump-we-asked-pollsters-why/">and you can even have a bollocksed up polling model with big consequences if you don’t have the right assumptions under the hood</a>, but more on that later.</p>
<p>So let’s talk about the Central Limit Theorem. John’s going to explain it simply and all the side notes are Steph translating John’s simple explanation for retular people.</p>
</div>
<div id="central-limit-theorem" class="section level1">
<h1>Central limit theorem</h1>
<p>The Central Limit Theorem is actually a collection of theorems: all have the same general idea, but it comes in different flavours, like icecream.</p>
<p>Basically, it all boils down to the fact that if you have a bunch of random observations that behave nicely, you can expect the mean of a properly behaved sample of those observations to act in predictable ways - if we have enough of those observations.</p>
<p>For all the parents out there, think of it like this: your children are often fractious and badly behaved at home, because they’re kids.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> But once you get to a certain number of your kids’ friends on a playdate, all of a sudden that behaviour gets alot better and <em>they go away and entertain themselves and you can have a cup of tea in the middle of the chaos</em>.</p>
<p>But you have to get to that critical mass before that’s possible - if there aren’t enough kids, or if you’ve got the wrong combination of kids, the wrong environment - it doesn’t work. The conditions have to be right. The central limit theorem is the same.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>The basic recipe is as follows:</p>
<pre><code>* You need a group of random numbers
* The random numbers have to be _well behaved_ in certain ways - in the ways they are collected and the process that generates them.
* Then good things, i.e. predictable things, happen.</code></pre>
<p>To try it John’s way, let’s look at the mathematical version. Lets
assume that</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\({\bf X} = (X_1,\ldots,X_n)\)</span> is a vector of <span class="math inline">\(n\)</span> random variables, i.e. just a bunch of random numbers in the column of a spreadsheet or something.</p></li>
<li><p>That the <span class="math inline">\({\bf X_i}\)</span> are indepedently drawn, that means the order in which those random numbers are chosen isn’t systematic in the sense that if I choose the first number, the second is predictable.</p></li>
<li><p>They all come from the same distribution- they’re all <em>generated in the same way</em>. They come from the same mechanism somehow - whether that’s height in humans, or car mileage or some other process with randomness.</p></li>
<li><p>They have a mean <span class="math inline">\(\mu = {\mathbb E}(X_i)\)</span> that exists, i.e. we’re putting boundaries on our <em>generating process</em> here. We’re saying that the mean of this process can’t be <em>infinite</em> or <em>unreal</em>. Think of this as the ‘not totally weird’ distributional assumption.</p></li>
<li><p>The series has a finite variance <span class="math inline">\(\sigma^2 = \mbox{Var}(X_i) &lt; \infty\)</span>, this is the ‘not totally weird assmumption, Part II’.</p></li>
</ol>
<p>Based on this set of conditions, we can then start talking about the <em>sample mean</em>.</p>
<p>Let <span class="math inline">\(\overline{X}\)</span> denote the average of a sample of the <span class="math inline">\(X_i\)</span>’s, i.e.,
<span class="math display">\[
\overline{X} = \frac{1}{n}\sum_{i=1}^n X_i 
\]</span></p>
<p>This is just maths for ’grab the Excel formula <code>AVG()</code>.</p>
<p>Then for for large enough <span class="math inline">\(n\)</span><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> we have
<span class="math display">\[
\overline{X} \stackrel{D}{\to} N\left(\mu,\frac{\sigma^2}{n} \right)
\]</span>
where <span class="math inline">\(\stackrel{D}{\to}\)</span> means <em>convergence in distribution</em>.</p>
</div>
<div id="understanding-the-convergence-in-distribution-bit-im-up-to-here-john" class="section level1">
<h1>Understanding the convergence in distribution bit I’M UP TO HERE JOHN</h1>
<p>To give some intuition about what “convergence in distribution” means suppose
we have <span class="math inline">\(N\)</span> collections of samples (of the same size <span class="math inline">\(n\)</span> and assumptions (1) to (5)),
that is,</p>
<ul>
<li><p><span class="math inline">\({\bf X}^{(1)} = (X_1^{(1)},\ldots,X_n^{(1)})\)</span></p></li>
<li><p><span class="math inline">\({\bf X}^{(2)} = (X_1^{(2)},\ldots,X_n^{(2)})\)</span></p></li>
<li><p><span class="math inline">\(\ldots\)</span></p></li>
<li><p><span class="math inline">\({\bf X}^{(N)} = (X_1^{(N)},\ldots,X_n^{(N)})\)</span></p></li>
</ul>
<p>and for each of these <span class="math inline">\(N\)</span> samples we calculate the mean</p>
<ul>
<li><p><span class="math inline">\(\overline{\bf X}^{(1)} = \frac{1}{n}\sum_{i=1}^n X_i^{(1)}\)</span></p></li>
<li><p><span class="math inline">\(\overline{\bf X}^{(2)} = \frac{1}{n}\sum_{i=1}^n X_i^{(2)}\)</span></p></li>
<li><p><span class="math inline">\(\ldots\)</span></p></li>
<li><p><span class="math inline">\(\overline{\bf X}^{(N)} = \frac{1}{n}\sum_{i=1}^n X_i^{(N)}\)</span></p></li>
</ul>
<p>then the collection of these <span class="math inline">\(\overline{\bf X}^{(1)},\ldots, \overline{\bf X}^{(N)}\)</span>
will be approximately normally distributed with mean <span class="math inline">\(\mu\)</span> and variance
<span class="math inline">\(\sigma^2/n\)</span>.</p>
<p>We want to show how the CLT works…. but on a distribution which is not normally
distributed.</p>
</div>
<div id="the-clt-in-action" class="section level1">
<h1>The CLT in action</h1>
<p>We will want to do this same thing multiple times so let’s put it in a
generic function.</p>
<pre class="r"><code>generate_plot_data &lt;- function(N,n_val,rdist,...)
{  
  # Initialize data for N datasets of size n
  X_mat &lt;- matrix(rdist(N*n_val, ...),N,n_val)
  
  # Calculate the means
  x_bar &lt;- apply(X_mat,1,mean)

  # Approximate the distribution of x_bar
  dens &lt;- density(x_bar)
  
  # Stores the data
  dat1 &lt;- cbind(x=dens$x,y=dens$y, n_val)
  colnames(dat1) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;n_val&quot;)
  
  # Approximate the mean and variance of the distribution
  mu &lt;- mean(X_mat)
  sigma2 &lt;- var(as.vector(X_mat))
  
  # Calculate the parameters of the CLT distribution
  mu_CLT     &lt;- mu
  sigma2_CLT &lt;- sigma2/n_val
  sigma_CLT  &lt;- sqrt(sigma2_CLT)
  
  # 
  xg &lt;- seq(mu_CLT - 5*sigma_CLT,mu_CLT + 5*sigma_CLT,,1000)
  fg &lt;- dnorm(xg,mu_CLT,sigma_CLT)
  dat2 &lt;- cbind(xg,fg,n_val)
  colnames(dat2) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;n_val&quot;)

  tib1 &lt;- as_tibble(dat1)
  tib2 &lt;- as_tibble(dat2)
  tib1 &lt;- tib1 %&gt;% add_column(method=&quot;exact&quot;)
  tib2 &lt;- tib2 %&gt;% add_column(method=&quot;CLT&quot;)
  tib &lt;- bind_rows(tib1,tib2)
  
  return(tib)
}</code></pre>
<p>Plot the the case when <span class="math inline">\(n=5\)</span></p>
<pre class="r"><code>k &lt;- 1.1
lambda &lt;- 10

# Call the function
tib &lt;- generate_plot_data(N=100000,n_val=2, rweibull, shape=k, scale=lambda)  %&gt;% add_column(dist=&quot;weibull&quot;)</code></pre>
<pre class="r"><code># Plot the results
g &lt;- ggplot(tib,aes(x=x,y=y,color=method)) +
  geom_line(size=1.5) +
  theme_bw() +
  labs(color=&quot;Methods&quot;,x=&#39;X bar&#39;,y=&#39;density&#39;)
g </code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The code used to create the animation below can be found<br />
<a href="CLT_supp.html">here</a>.</p>
<center>
<img src="two_by_three.gif" style="width:75%">
</center>
</div>
<div id="a-practical-example" class="section level1">
<h1>A practical example</h1>
<pre class="r"><code>library(Ecdat)</code></pre>
<pre><code>## Loading required package: Ecfun</code></pre>
<pre><code>## 
## Attaching package: &#39;Ecfun&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     sign</code></pre>
<pre><code>## 
## Attaching package: &#39;Ecdat&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:datasets&#39;:
## 
##     Orange</code></pre>
<pre class="r"><code>N &lt;- 1000

trapint &lt;- function(xgrid, fgrid) 
{
    ng &lt;- length(xgrid)
    xvec &lt;- xgrid[2:ng] - xgrid[1:(ng - 1)]
    fvec &lt;- fgrid[1:(ng - 1)] + fgrid[2:ng]
    integ &lt;- sum(xvec * fvec)/2
    return(integ)
}

X &lt;- VietNamI %&gt;% na.omit()

vn &lt;- seq(10,200,by=5)
mErr &lt;- matrix(0,length(vn),ncol(X))

for (k in 1:ncol(X))
{
  if (is.numeric(X[,k])) {
    
    x &lt;- X[,k]
    n &lt;- length(x)
    
    
    
    mu &lt;- mean(x)
    sigma2 &lt;- var(x)
    
    
    for (j in 1:length(vn))
    {
      x.bar &lt;- c()
      for (i in 1:N)
      {
        inds &lt;- sample(n,vn[j])
        x.samp &lt;- x[inds]
        x.bar[i] &lt;- mean(x.samp)
      }
      
      dens &lt;- density(x.bar)
      #plot(dens)
      
      mu_CLT &lt;- mu
      sigma2_CLT &lt;- sigma2/vn[j]
      sigma_CLT &lt;- sqrt(sigma2_CLT)
      
      xg &lt;- dens$x
      yg &lt;- dnorm(xg,mu_CLT,sigma_CLT)
      #lines(x,y,col=&quot;red&quot;,lwd=2)
    
      mErr[j,k] &lt;- 0.5*trapint(xg,abs(yg - dens$y))
      
      cat(j,k,vn[j],colnames(X)[k],mErr[j,k],&quot;\n&quot;)
    }
    
    plot(vn,mErr[,k],type=&quot;l&quot;) 
  }
}</code></pre>
<pre><code>## 1 1 10 pharvis 0.1828665 
## 2 1 15 pharvis 0.1593729 
## 3 1 20 pharvis 0.1327541 
## 4 1 25 pharvis 0.1260699 
## 5 1 30 pharvis 0.1149613 
## 6 1 35 pharvis 0.09551499 
## 7 1 40 pharvis 0.1258864 
## 8 1 45 pharvis 0.1052346 
## 9 1 50 pharvis 0.1083818 
## 10 1 55 pharvis 0.09202548 
## 11 1 60 pharvis 0.09894423 
## 12 1 65 pharvis 0.106095 
## 13 1 70 pharvis 0.0863909 
## 14 1 75 pharvis 0.08404542 
## 15 1 80 pharvis 0.08538005 
## 16 1 85 pharvis 0.07705171 
## 17 1 90 pharvis 0.06252924 
## 18 1 95 pharvis 0.09003062 
## 19 1 100 pharvis 0.07682404 
## 20 1 105 pharvis 0.07508646 
## 21 1 110 pharvis 0.09175523 
## 22 1 115 pharvis 0.06377045 
## 23 1 120 pharvis 0.06138987 
## 24 1 125 pharvis 0.05655031 
## 25 1 130 pharvis 0.04263543 
## 26 1 135 pharvis 0.05754709 
## 27 1 140 pharvis 0.04721017 
## 28 1 145 pharvis 0.04233888 
## 29 1 150 pharvis 0.06706791 
## 30 1 155 pharvis 0.06039721 
## 31 1 160 pharvis 0.06555821 
## 32 1 165 pharvis 0.06730412 
## 33 1 170 pharvis 0.0731288 
## 34 1 175 pharvis 0.04404 
## 35 1 180 pharvis 0.0682443 
## 36 1 185 pharvis 0.04460442 
## 37 1 190 pharvis 0.04580113 
## 38 1 195 pharvis 0.05844029 
## 39 1 200 pharvis 0.07182936</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre><code>## 1 2 10 lnhhexp 0.02858385 
## 2 2 15 lnhhexp 0.02268682 
## 3 2 20 lnhhexp 0.0237148 
## 4 2 25 lnhhexp 0.03349921 
## 5 2 30 lnhhexp 0.03364062 
## 6 2 35 lnhhexp 0.0359205 
## 7 2 40 lnhhexp 0.03953959 
## 8 2 45 lnhhexp 0.02230228 
## 9 2 50 lnhhexp 0.02706833 
## 10 2 55 lnhhexp 0.0286123 
## 11 2 60 lnhhexp 0.02500035 
## 12 2 65 lnhhexp 0.03580943 
## 13 2 70 lnhhexp 0.02265368 
## 14 2 75 lnhhexp 0.02508498 
## 15 2 80 lnhhexp 0.03137443 
## 16 2 85 lnhhexp 0.03456398 
## 17 2 90 lnhhexp 0.03065574 
## 18 2 95 lnhhexp 0.02630332 
## 19 2 100 lnhhexp 0.02051842 
## 20 2 105 lnhhexp 0.03661474 
## 21 2 110 lnhhexp 0.04745824 
## 22 2 115 lnhhexp 0.027486 
## 23 2 120 lnhhexp 0.02607828 
## 24 2 125 lnhhexp 0.02697429 
## 25 2 130 lnhhexp 0.03958545 
## 26 2 135 lnhhexp 0.03041166 
## 27 2 140 lnhhexp 0.03734235 
## 28 2 145 lnhhexp 0.05629619 
## 29 2 150 lnhhexp 0.04118259 
## 30 2 155 lnhhexp 0.03411006 
## 31 2 160 lnhhexp 0.03143088 
## 32 2 165 lnhhexp 0.01568343 
## 33 2 170 lnhhexp 0.01823139 
## 34 2 175 lnhhexp 0.03715915 
## 35 2 180 lnhhexp 0.03197391 
## 36 2 185 lnhhexp 0.03256736 
## 37 2 190 lnhhexp 0.02747832 
## 38 2 195 lnhhexp 0.02958646 
## 39 2 200 lnhhexp 0.03641624</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<pre><code>## 1 3 10 age 0.06005602 
## 2 3 15 age 0.04604646 
## 3 3 20 age 0.05987001 
## 4 3 25 age 0.0359188 
## 5 3 30 age 0.0331612 
## 6 3 35 age 0.05767375 
## 7 3 40 age 0.02660182 
## 8 3 45 age 0.02281899 
## 9 3 50 age 0.03889688 
## 10 3 55 age 0.03996309 
## 11 3 60 age 0.0370044 
## 12 3 65 age 0.03969197 
## 13 3 70 age 0.04328204 
## 14 3 75 age 0.01722285 
## 15 3 80 age 0.03111729 
## 16 3 85 age 0.05047663 
## 17 3 90 age 0.022043 
## 18 3 95 age 0.0328243 
## 19 3 100 age 0.03596133 
## 20 3 105 age 0.03533892 
## 21 3 110 age 0.04506135 
## 22 3 115 age 0.03759997 
## 23 3 120 age 0.02928963 
## 24 3 125 age 0.0270009 
## 25 3 130 age 0.0226759 
## 26 3 135 age 0.03032116 
## 27 3 140 age 0.05340585 
## 28 3 145 age 0.03442817 
## 29 3 150 age 0.02805355 
## 30 3 155 age 0.03271991 
## 31 3 160 age 0.04334077 
## 32 3 165 age 0.03670621 
## 33 3 170 age 0.03176882 
## 34 3 175 age 0.02797582 
## 35 3 180 age 0.04377991 
## 36 3 185 age 0.02965952 
## 37 3 190 age 0.03530327 
## 38 3 195 age 0.02034863 
## 39 3 200 age 0.03757573</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-3.png" width="672" /></p>
<pre><code>## 1 5 10 married 0.07766958 
## 2 5 15 married 0.07689595 
## 3 5 20 married 0.04197932 
## 4 5 25 married 0.02731548 
## 5 5 30 married 0.02546879 
## 6 5 35 married 0.05798646 
## 7 5 40 married 0.02991558 
## 8 5 45 married 0.0247856 
## 9 5 50 married 0.04279186 
## 10 5 55 married 0.0316752 
## 11 5 60 married 0.04097558 
## 12 5 65 married 0.03041101 
## 13 5 70 married 0.0266947 
## 14 5 75 married 0.02432966 
## 15 5 80 married 0.03537033 
## 16 5 85 married 0.02280966 
## 17 5 90 married 0.04760328 
## 18 5 95 married 0.03952596 
## 19 5 100 married 0.03668578 
## 20 5 105 married 0.02566679 
## 21 5 110 married 0.05612692 
## 22 5 115 married 0.04484489 
## 23 5 120 married 0.03767158 
## 24 5 125 married 0.03299078 
## 25 5 130 married 0.02312951 
## 26 5 135 married 0.04231115 
## 27 5 140 married 0.01739545 
## 28 5 145 married 0.01917237 
## 29 5 150 married 0.02559492 
## 30 5 155 married 0.02966021 
## 31 5 160 married 0.03650651 
## 32 5 165 married 0.0404065 
## 33 5 170 married 0.02817811 
## 34 5 175 married 0.0345113 
## 35 5 180 married 0.02026841 
## 36 5 185 married 0.03283529 
## 37 5 190 married 0.03153192 
## 38 5 195 married 0.01984509 
## 39 5 200 married 0.01652906</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-4.png" width="672" /></p>
<pre><code>## 1 6 10 educ 0.02442119 
## 2 6 15 educ 0.0369141 
## 3 6 20 educ 0.04578768 
## 4 6 25 educ 0.03130477 
## 5 6 30 educ 0.02978334 
## 6 6 35 educ 0.03611878 
## 7 6 40 educ 0.02760543 
## 8 6 45 educ 0.0381212 
## 9 6 50 educ 0.02527684 
## 10 6 55 educ 0.02679559 
## 11 6 60 educ 0.04416787 
## 12 6 65 educ 0.02153537 
## 13 6 70 educ 0.03396963 
## 14 6 75 educ 0.05003604 
## 15 6 80 educ 0.03056716 
## 16 6 85 educ 0.03726238 
## 17 6 90 educ 0.0339134 
## 18 6 95 educ 0.0337129 
## 19 6 100 educ 0.01643456 
## 20 6 105 educ 0.02879363 
## 21 6 110 educ 0.03033641 
## 22 6 115 educ 0.03758668 
## 23 6 120 educ 0.025365 
## 24 6 125 educ 0.02202368 
## 25 6 130 educ 0.02065265 
## 26 6 135 educ 0.02460571 
## 27 6 140 educ 0.03723142 
## 28 6 145 educ 0.02011694 
## 29 6 150 educ 0.02697472 
## 30 6 155 educ 0.01930626 
## 31 6 160 educ 0.02554213 
## 32 6 165 educ 0.02691153 
## 33 6 170 educ 0.03209842 
## 34 6 175 educ 0.01904031 
## 35 6 180 educ 0.02797094 
## 36 6 185 educ 0.03443833 
## 37 6 190 educ 0.04285174 
## 38 6 195 educ 0.02854382 
## 39 6 200 educ 0.0364633</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-5.png" width="672" /></p>
<pre><code>## 1 7 10 illness 0.0495483 
## 2 7 15 illness 0.07553944 
## 3 7 20 illness 0.06727432 
## 4 7 25 illness 0.039403 
## 5 7 30 illness 0.05484281 
## 6 7 35 illness 0.03270475 
## 7 7 40 illness 0.04136437 
## 8 7 45 illness 0.05485486 
## 9 7 50 illness 0.0339591 
## 10 7 55 illness 0.03680073 
## 11 7 60 illness 0.047732 
## 12 7 65 illness 0.06885375 
## 13 7 70 illness 0.0484034 
## 14 7 75 illness 0.04025948 
## 15 7 80 illness 0.01761142 
## 16 7 85 illness 0.03115657 
## 17 7 90 illness 0.04050294 
## 18 7 95 illness 0.04524012 
## 19 7 100 illness 0.02397938 
## 20 7 105 illness 0.03064558 
## 21 7 110 illness 0.02649993 
## 22 7 115 illness 0.02289549 
## 23 7 120 illness 0.04406765 
## 24 7 125 illness 0.01941848 
## 25 7 130 illness 0.03897186 
## 26 7 135 illness 0.04261174 
## 27 7 140 illness 0.05024244 
## 28 7 145 illness 0.02604727 
## 29 7 150 illness 0.0243997 
## 30 7 155 illness 0.03369603 
## 31 7 160 illness 0.0351548 
## 32 7 165 illness 0.02363816 
## 33 7 170 illness 0.02615788 
## 34 7 175 illness 0.02895967 
## 35 7 180 illness 0.0231767 
## 36 7 185 illness 0.0395803 
## 37 7 190 illness 0.0196493 
## 38 7 195 illness 0.02488213 
## 39 7 200 illness 0.03072223</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-6.png" width="672" /></p>
<pre><code>## 1 8 10 injury 0.5708244 
## 2 8 15 injury 0.5506738 
## 3 8 20 injury 0.5234225 
## 4 8 25 injury 0.5040409 
## 5 8 30 injury 0.4666167 
## 6 8 35 injury 0.4574701 
## 7 8 40 injury 0.4343682 
## 8 8 45 injury 0.4334686 
## 9 8 50 injury 0.3982207 
## 10 8 55 injury 0.3799664 
## 11 8 60 injury 0.3853136 
## 12 8 65 injury 0.3818913 
## 13 8 70 injury 0.3751098 
## 14 8 75 injury 0.3778316 
## 15 8 80 injury 0.3750655 
## 16 8 85 injury 0.3745797 
## 17 8 90 injury 0.3777972 
## 18 8 95 injury 0.3771116 
## 19 8 100 injury 0.2733045 
## 20 8 105 injury 0.3786382 
## 21 8 110 injury 0.2624557 
## 22 8 115 injury 0.2287668 
## 23 8 120 injury 0.2440037 
## 24 8 125 injury 0.2251326 
## 25 8 130 injury 0.2101805 
## 26 8 135 injury 0.2290993 
## 27 8 140 injury 0.1945024 
## 28 8 145 injury 0.1948162 
## 29 8 150 injury 0.3763687 
## 30 8 155 injury 0.3731588 
## 31 8 160 injury 0.3705809 
## 32 8 165 injury 0.37421 
## 33 8 170 injury 0.3731425 
## 34 8 175 injury 0.3705177 
## 35 8 180 injury 0.1358498 
## 36 8 185 injury 0.139248 
## 37 8 190 injury 0.1468159 
## 38 8 195 injury 0.1476047 
## 39 8 200 injury 0.1283169</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-7.png" width="672" /></p>
<pre><code>## 1 9 10 illdays 0.1201853 
## 2 9 15 illdays 0.1189809 
## 3 9 20 illdays 0.1092106 
## 4 9 25 illdays 0.06463426 
## 5 9 30 illdays 0.08657401 
## 6 9 35 illdays 0.06508944 
## 7 9 40 illdays 0.07391458 
## 8 9 45 illdays 0.06591695 
## 9 9 50 illdays 0.06305761 
## 10 9 55 illdays 0.04809549 
## 11 9 60 illdays 0.04433832 
## 12 9 65 illdays 0.0623081 
## 13 9 70 illdays 0.05754355 
## 14 9 75 illdays 0.03083813 
## 15 9 80 illdays 0.03217911 
## 16 9 85 illdays 0.02826183 
## 17 9 90 illdays 0.05968018 
## 18 9 95 illdays 0.06617412 
## 19 9 100 illdays 0.05519053 
## 20 9 105 illdays 0.02827084 
## 21 9 110 illdays 0.03396736 
## 22 9 115 illdays 0.05930657 
## 23 9 120 illdays 0.0547335 
## 24 9 125 illdays 0.04082126 
## 25 9 130 illdays 0.04465386 
## 26 9 135 illdays 0.03225221 
## 27 9 140 illdays 0.03251059 
## 28 9 145 illdays 0.04622059 
## 29 9 150 illdays 0.03903891 
## 30 9 155 illdays 0.04166697 
## 31 9 160 illdays 0.04741654 
## 32 9 165 illdays 0.03316501 
## 33 9 170 illdays 0.02965199 
## 34 9 175 illdays 0.06060091 
## 35 9 180 illdays 0.04076304 
## 36 9 185 illdays 0.03211816 
## 37 9 190 illdays 0.04682974 
## 38 9 195 illdays 0.02838235 
## 39 9 200 illdays 0.02412357</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-8.png" width="672" /></p>
<pre><code>## 1 10 10 actdays 0.4820809 
## 2 10 15 actdays 0.4795024 
## 3 10 20 actdays 0.4755247 
## 4 10 25 actdays 0.4493262 
## 5 10 30 actdays 0.4326796 
## 6 10 35 actdays 0.4694989 
## 7 10 40 actdays 0.5933227 
## 8 10 45 actdays 0.6086347 
## 9 10 50 actdays 0.5351186 
## 10 10 55 actdays 0.5179336 
## 11 10 60 actdays 0.5104708 
## 12 10 65 actdays 0.4780555 
## 13 10 70 actdays 0.4627004 
## 14 10 75 actdays 0.4460461 
## 15 10 80 actdays 0.4645414 
## 16 10 85 actdays 0.4324279 
## 17 10 90 actdays 0.4119209 
## 18 10 95 actdays 0.4180139 
## 19 10 100 actdays 0.3726742 
## 20 10 105 actdays 0.3995021 
## 21 10 110 actdays 0.4013277 
## 22 10 115 actdays 0.3753143 
## 23 10 120 actdays 0.3484557 
## 24 10 125 actdays 0.3674577 
## 25 10 130 actdays 0.3429206 
## 26 10 135 actdays 0.3668906 
## 27 10 140 actdays 0.3215619 
## 28 10 145 actdays 0.3150897 
## 29 10 150 actdays 0.3014786 
## 30 10 155 actdays 0.2739514 
## 31 10 160 actdays 0.2904161 
## 32 10 165 actdays 0.3075803 
## 33 10 170 actdays 0.3092657 
## 34 10 175 actdays 0.2735007 
## 35 10 180 actdays 0.2672726 
## 36 10 185 actdays 0.2575972 
## 37 10 190 actdays 0.2689494 
## 38 10 195 actdays 0.2623027 
## 39 10 200 actdays 0.2672</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-9.png" width="672" /></p>
<pre><code>## 1 11 10 insurance 0.3704532 
## 2 11 15 insurance 0.1248356 
## 3 11 20 insurance 0.09372333 
## 4 11 25 insurance 0.08411136 
## 5 11 30 insurance 0.0665754 
## 6 11 35 insurance 0.02369982 
## 7 11 40 insurance 0.04942983 
## 8 11 45 insurance 0.04272258 
## 9 11 50 insurance 0.04540087 
## 10 11 55 insurance 0.0250178 
## 11 11 60 insurance 0.03227212 
## 12 11 65 insurance 0.03716307 
## 13 11 70 insurance 0.02513862 
## 14 11 75 insurance 0.02449695 
## 15 11 80 insurance 0.03306872 
## 16 11 85 insurance 0.02655837 
## 17 11 90 insurance 0.0297081 
## 18 11 95 insurance 0.02916112 
## 19 11 100 insurance 0.02468415 
## 20 11 105 insurance 0.02960588 
## 21 11 110 insurance 0.03369973 
## 22 11 115 insurance 0.05416351 
## 23 11 120 insurance 0.0300696 
## 24 11 125 insurance 0.03296473 
## 25 11 130 insurance 0.04512319 
## 26 11 135 insurance 0.02987727 
## 27 11 140 insurance 0.0284041 
## 28 11 145 insurance 0.03788011 
## 29 11 150 insurance 0.02680373 
## 30 11 155 insurance 0.03212679 
## 31 11 160 insurance 0.03365495 
## 32 11 165 insurance 0.05150302 
## 33 11 170 insurance 0.05028667 
## 34 11 175 insurance 0.02987331 
## 35 11 180 insurance 0.02616723 
## 36 11 185 insurance 0.03203886 
## 37 11 190 insurance 0.0284823 
## 38 11 195 insurance 0.03632698 
## 39 11 200 insurance 0.0404972</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-10.png" width="672" /></p>
<pre><code>## 1 12 10 commune 0.01951257 
## 2 12 15 commune 0.02838196 
## 3 12 20 commune 0.03097052 
## 4 12 25 commune 0.03221967 
## 5 12 30 commune 0.03276158 
## 6 12 35 commune 0.04287274 
## 7 12 40 commune 0.02918231 
## 8 12 45 commune 0.03321548 
## 9 12 50 commune 0.023123 
## 10 12 55 commune 0.03331904 
## 11 12 60 commune 0.02683258 
## 12 12 65 commune 0.03710526 
## 13 12 70 commune 0.03110304 
## 14 12 75 commune 0.03866229 
## 15 12 80 commune 0.02898625 
## 16 12 85 commune 0.03445611 
## 17 12 90 commune 0.03266507 
## 18 12 95 commune 0.03205339 
## 19 12 100 commune 0.04171347 
## 20 12 105 commune 0.05353885 
## 21 12 110 commune 0.0278453 
## 22 12 115 commune 0.02493967 
## 23 12 120 commune 0.02759683 
## 24 12 125 commune 0.02784632 
## 25 12 130 commune 0.02862106 
## 26 12 135 commune 0.02693666 
## 27 12 140 commune 0.02834403 
## 28 12 145 commune 0.03235948 
## 29 12 150 commune 0.03280565 
## 30 12 155 commune 0.03042818 
## 31 12 160 commune 0.02873496 
## 32 12 165 commune 0.0394425 
## 33 12 170 commune 0.02233814 
## 34 12 175 commune 0.03317316 
## 35 12 180 commune 0.04371201 
## 36 12 185 commune 0.01431567 
## 37 12 190 commune 0.0314957 
## 38 12 195 commune 0.03235681 
## 39 12 200 commune 0.02800398</code></pre>
<p><img src="/post/CLT_orig_files/figure-html/unnamed-chunk-4-11.png" width="672" /></p>
</div>
<div id="why-it-works---part-1" class="section level1">
<h1>Why it works - Part 1</h1>
<p>Assume <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> exists.
Define
<span class="math display">\[
Y_i = \frac{X_i - \mu}{\sigma}
\]</span>
Define
<span class="math display">\[
Z = \frac{1}{\sqrt{n}} \sum_{i=1}^n Y_i
\]</span>
Using properties of expectations and variances it can be shown
<span class="math display">\[
{\mathbb E}(Z) = 0 
\qquad \mbox{and} \qquad 
\mbox{Var}(Z) = 1. 
\]</span>
We are going to use two special functions</p>
<ul>
<li><p><strong>Moment generating functions</strong>: The moment generating function (MGF)
of a RV <span class="math inline">\(X\)</span> as a function of <span class="math inline">\(t\)</span> is defined as
<span class="math display">\[
M_X(t) = {\mathbb E}\left[ \exp(tX) \right]
\]</span></p></li>
<li><p><strong>Cumulant generating functions</strong>: The cumulant generating function (CGF)
of a RV <span class="math inline">\(X\)</span> as a function of <span class="math inline">\(t\)</span> is defined as
<span class="math display">\[
K_X(t) = \log M_X(t)
\]</span></p></li>
</ul>
<p>Some useful properties of MGFs and CGFs include:</p>
<ul>
<li><p>The MGF and CGF uniquely identify a distribution.</p></li>
<li><p>The CGF for the <span class="math inline">\(X\sim N(0,1)\)</span> is <span class="math inline">\(K_X(t) = t^2/2\)</span>.</p></li>
<li><p><span class="math inline">\(K_Y&#39;(0) = {\mathbb E}(Y)\)</span> and K_Y’’(0) = (Y)$.</p></li>
</ul>
<p>Now the MGF of <span class="math inline">\(Z\)</span> defined above is:
<span class="math display">\[
\begin{array}{rl}
M_{Z}(t) 
&amp; \displaystyle = {\mathbb E}\left[ \exp(tZ) \right]
&amp; \qquad \mbox{(Definition)}
\\
&amp; \displaystyle = {\mathbb E}\left[ \exp\left( \frac{t}{\sqrt{n}} \sum_{i=1}^n Y_i  \right) \right]
&amp; \qquad \mbox{(Definition)}
\\
&amp; \displaystyle = \prod_{i=1}^n {\mathbb E}\left[ \exp\left( \frac{t}{\sqrt{n}}  Y_i  \right) \right]
&amp; \qquad \mbox{(Independence and properties of exp)}
\\
&amp; \displaystyle = \prod_{i=1}^n  \left[  M_Y\left( \frac{t}{\sqrt{n}} \right) \right]^n 
&amp; \qquad \mbox{(Identically distributed)}
\end{array} 
\]</span>
Hence, the CGF of <span class="math inline">\(Z\)</span> satisfies:
<span class="math display">\[
\begin{array}{rll}
K_Z(t) 
&amp; = \log M_{Z}(t)  &amp; \mbox{(Definition)}
\\
&amp; = n \log M_Y\left( \frac{t}{\sqrt{n}} \right) &amp; \mbox{(From Above)}
\\ 
&amp; = n K_Y\left( \frac{t}{\sqrt{n}} \right) &amp; \mbox{(Definition)}
\end{array}
\]</span></p>
<p>We can also establish that:
<span class="math display">\[
K_Y&#39;(0) = {\mathbb E}(Y) = 0 
\qquad \mbox{and} \qquad 
K_Y&#39;&#39;(0) = \mbox{Var}(Y) = 1. 
\]</span></p>
<pre class="marginfigure"><code>__L&#39;Hopital&#39;s rule__ (under appropriate conditions) that
that for differentiable functions $f(x)$ and $g(x)$ 
that if $\lim_{x\to c} f(x)/g(x),$
is an indetermiant form, e.g., $0/0$, $\infty/\infty$
then
$$
\displaystyle \lim_{x\to c} \frac{f(x)}{g(x)} = \lim_{x\to c} \frac{f&#39;(x)}{g&#39;(x)}.
$$
  
assuming the right hand side exists.</code></pre>
<p>Now we use
<a href="https://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule">L’Hopital’s rule</a>
twice to obtain
<span class="math display">\[
\begin{array}{rl}
\displaystyle \lim_{n\to\infty} K_Z(t)
&amp; \displaystyle = \lim_{n\to\infty} n K_Y\left( \frac{t}{\sqrt{n}} \right) 
\\
&amp; \displaystyle = \lim_{\Delta\to 0} \frac{ K_Y\left( \Delta t \right)}{\Delta^2} 
\\
&amp; \displaystyle = \lim_{\Delta\to 0} \frac{ t K_Y&#39;\left( \Delta t \right)}{2\Delta} \qquad \mbox{(L&#39;Hopital&#39;s rule)} 
\\
&amp; \displaystyle = \lim_{\Delta\to 0} \frac{ t^2 K_Y&#39;&#39;\left( \Delta t \right)}{2} \qquad \mbox{(L&#39;Hopital&#39;s rule)}
\\
&amp; = \displaystyle \frac{t^2}{2}
\end{array}
\]</span></p>
<p>which is the cumulant generating function of the nomral distribution.
Hence, the CGF of <span class="math inline">\(Z\)</span> approaches that of a normal distirubiton.</p>
<div align="center">
<p><iframe width="560" height="315" src="https://player.vimeo.com/video/75089338" frameborder="0" allowfullscreen>
</iframe></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Children are the ultimate random variables. They have their moments. You can see why we’re obsessed with behaviour.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Our forthcoming parenting book <em>Parenting by the numbers</em> is due out any time now. All we need is a publisher. It’s going to be a hit.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Remember you need enough kids before they entertain themselves. That’s what we mean about ‘large enough n’: a big enough sample size.<a href="#fnref3" class="footnote-back">↩</a></p></li>
</ol>
</div>
